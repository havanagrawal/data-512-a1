{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:19.453434Z",
     "start_time": "2018-10-17T08:05:18.779815Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use two Wikimedia API endpoints:\n",
    "  1. [Legacy Pagecounts API](https://wikitech.wikimedia.org/wiki/Analytics/AQS/Legacy_Pagecounts)\n",
    "  2. [Pageviews API](https://wikitech.wikimedia.org/wiki/Analytics/AQS/Pageviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:19.459625Z",
     "start_time": "2018-10-17T08:05:19.456182Z"
    }
   },
   "outputs": [],
   "source": [
    "ENDPOINT_ROOT = \"https://wikimedia.org/api/rest_v1/metrics/\"\n",
    "ENDPOINT_LEGACY = ENDPOINT_ROOT + 'legacy/pagecounts/aggregate/{project}/{access-site}/{granularity}/{start}/{end}'\n",
    "ENDPOINT_PAGEVIEW = ENDPOINT_ROOT + 'pageviews/aggregate/{project}/{access}/{agent}/{granularity}/{start}/{end}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:19.467362Z",
     "start_time": "2018-10-17T08:05:19.461858Z"
    }
   },
   "outputs": [],
   "source": [
    "COMMON_PARAMS = {\n",
    "    \"project\" : \"en.wikipedia.org\",\n",
    "    \"granularity\" : \"monthly\",\n",
    "}\n",
    "\n",
    "OUTPUT_JSON_DIR = \"json\"\n",
    "OUTPUT_CSV_DIR = \"csv\"\n",
    "\n",
    "HEADERS = {\n",
    "    'User-Agent': 'https://github.com/havanagrawal',\n",
    "    'From': 'agrawh@uw.edu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:19.481863Z",
     "start_time": "2018-10-17T08:05:19.469620Z"
    }
   },
   "outputs": [],
   "source": [
    "# Delete the directory if it already exists, and then recreate it\n",
    "if os.path.exists(OUTPUT_JSON_DIR):\n",
    "    shutil.rmtree(OUTPUT_JSON_DIR)\n",
    "    \n",
    "if os.path.exists(OUTPUT_CSV_DIR):\n",
    "    shutil.rmtree(OUTPUT_CSV_DIR)\n",
    "    \n",
    "os.mkdir(OUTPUT_JSON_DIR)\n",
    "os.mkdir(OUTPUT_CSV_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:19.493607Z",
     "start_time": "2018-10-17T08:05:19.485603Z"
    }
   },
   "outputs": [],
   "source": [
    "def api_call(endpoint, parameters):\n",
    "    call = requests.get(endpoint.format(**parameters), headers=HEADERS)\n",
    "    response = call.json()\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:19.508875Z",
     "start_time": "2018-10-17T08:05:19.500615Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_output_file_path(api_type, accesstype, start, end):\n",
    "    filename = \"{api_type}_{accesstype}_{start}-{end}.json\".format(api_type=api_type, accesstype=accesstype, start=start, end=end)\n",
    "    return os.path.join(OUTPUT_JSON_DIR, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:19.524111Z",
     "start_time": "2018-10-17T08:05:19.511182Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_to_json(data, filename):\n",
    "    data_string = json.dumps(data, indent=2)\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(data_string)\n",
    "        \n",
    "def read_from_json(filename):\n",
    "    data = {}\n",
    "    with open(filename, \"r\") as f:\n",
    "        data = json.loads(f.read())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Legacy PageCounts Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:19.535409Z",
     "start_time": "2018-10-17T08:05:19.526227Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_legacy_page_count_data(access_site, start, end):\n",
    "    params = {\n",
    "        \"access-site\" : access_site,\n",
    "        \"start\" : start,\n",
    "        \"end\" : end\n",
    "    }\n",
    "    params.update(COMMON_PARAMS)\n",
    "    data = api_call(ENDPOINT_LEGACY, params)\n",
    "    output_filepath = get_output_file_path(\"pagecounts\", access_site, start, end)\n",
    "    \n",
    "    write_to_json(data, output_filepath)\n",
    "    \n",
    "    return output_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:19.934278Z",
     "start_time": "2018-10-17T08:05:19.538273Z"
    }
   },
   "outputs": [],
   "source": [
    "start, end = \"2007120100\", \"2016080100\"\n",
    "pagecount_desktop_file = get_legacy_page_count_data('desktop-site', start, end)\n",
    "pagecount_mobile_file = get_legacy_page_count_data('mobile-site', start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting PageViews Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:19.947196Z",
     "start_time": "2018-10-17T08:05:19.937173Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_page_view_data(access_site, start, end):\n",
    "    params = {\n",
    "        \"access\" : access_site,\n",
    "        \"start\" : start,\n",
    "        \"end\" : end,\n",
    "        \"agent\": \"user\"\n",
    "    }\n",
    "    params.update(COMMON_PARAMS)\n",
    "    data = api_call(ENDPOINT_PAGEVIEW, params)\n",
    "    output_filepath = get_output_file_path(\"pageviews\", access_site, start, end)\n",
    "    \n",
    "    write_to_json(data, output_filepath)\n",
    "    \n",
    "    return output_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:20.505329Z",
     "start_time": "2018-10-17T08:05:19.949306Z"
    }
   },
   "outputs": [],
   "source": [
    "start, end = \"2015070100\", \"2018100100\"\n",
    "pageview_desktop_file = get_page_view_data(\"desktop\", start, end)\n",
    "pageview_mobile_app_file = get_page_view_data(\"mobile-app\", start, end)\n",
    "pageview_mobile_site_file = get_page_view_data(\"mobile-web\", start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:20.521418Z",
     "start_time": "2018-10-17T08:05:20.508664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pageviews_mobile-app_2015070100-2018100100.json',\n",
       " 'pagecounts_mobile-site_2007120100-2016080100.json',\n",
       " 'pageviews_desktop_2015070100-2018100100.json',\n",
       " 'pagecounts_desktop-site_2007120100-2016080100.json',\n",
       " 'pageviews_mobile-web_2015070100-2018100100.json']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should have 5 files\n",
    "output_files = os.listdir(OUTPUT_JSON_DIR)\n",
    "assert len(output_files) == 5\n",
    "output_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:20.535727Z",
     "start_time": "2018-10-17T08:05:20.526068Z"
    }
   },
   "outputs": [],
   "source": [
    "def year(ts):\n",
    "    return int(ts[:4])\n",
    "\n",
    "def month(ts):\n",
    "    return int(ts[4:6])\n",
    "\n",
    "def yyyymm(ts):\n",
    "    return str(year(ts)) + str(month(ts)).rjust(2, \"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the generated JSON files from the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:20.548344Z",
     "start_time": "2018-10-17T08:05:20.539126Z"
    }
   },
   "outputs": [],
   "source": [
    "pageviews_mobile_app = read_from_json('json/pageviews_mobile-app_2015070100-2018100100.json')\n",
    "pageviews_mobile_site = read_from_json('json/pageviews_mobile-web_2015070100-2018100100.json')\n",
    "pageviews_desktop_site = read_from_json(\"json/pageviews_desktop_2015070100-2018100100.json\")\n",
    "\n",
    "pagecount_mobile = read_from_json(\"json/pagecounts_mobile-site_2007120100-2016080100.json\")\n",
    "pagecount_desktop_site = read_from_json(\"json/pagecounts_desktop-site_2007120100-2016080100.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:20.556008Z",
     "start_time": "2018-10-17T08:05:20.551436Z"
    }
   },
   "outputs": [],
   "source": [
    "pageviews_mobile_views = defaultdict(int)\n",
    "pageviews_desktop_views = defaultdict(int)\n",
    "\n",
    "pagecounts_mobile_views = defaultdict(int)\n",
    "pagecounts_desktop_views = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:20.566725Z",
     "start_time": "2018-10-17T08:05:20.559094Z"
    }
   },
   "outputs": [],
   "source": [
    "def fill_dict(src_data, dest_dict):\n",
    "    for item in src_data['items']:\n",
    "        key = yyyymm(item['timestamp'])\n",
    "        if 'views' in item:\n",
    "            dest_dict[key] += item['views']\n",
    "        else:\n",
    "            dest_dict[key] += item['count']\n",
    "            \n",
    "def make_df(d, value_key):\n",
    "    return pd.DataFrame({'yyyymm': list(d.keys()), value_key: list(d.values())})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the results from the mobile site and mobile web app for the page view data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:20.573910Z",
     "start_time": "2018-10-17T08:05:20.568760Z"
    }
   },
   "outputs": [],
   "source": [
    "fill_dict(pageviews_mobile_app, pageviews_mobile_views)\n",
    "fill_dict(pageviews_mobile_site, pageviews_mobile_views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The others go into their respective independent counting dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:20.588237Z",
     "start_time": "2018-10-17T08:05:20.578422Z"
    }
   },
   "outputs": [],
   "source": [
    "fill_dict(pageviews_desktop_site, pageviews_desktop_views)\n",
    "\n",
    "fill_dict(pagecount_desktop_site, pagecounts_desktop_views)\n",
    "fill_dict(pagecount_mobile, pagecounts_mobile_views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the desired output is a CSV file, the most convenient way to do so would be to convert the JSON into DataFrames, process and merge them, and then write the DataFrame into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:20.611382Z",
     "start_time": "2018-10-17T08:05:20.591834Z"
    }
   },
   "outputs": [],
   "source": [
    "pv_mobile_df = make_df(pageviews_mobile_views, 'pageview_mobile_views')\n",
    "pc_mobile_df = make_df(pagecounts_mobile_views, 'pagecount_mobile_views')\n",
    "\n",
    "pv_desktop_df = make_df(pageviews_desktop_views, 'pageview_desktop_views')\n",
    "pc_desktop_df = make_df(pagecounts_desktop_views, 'pagecount_desktop_views')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply a `reduce` function that merges all of the data frames into a single one, using the year-month pair as key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:20.649589Z",
     "start_time": "2018-10-17T08:05:20.616410Z"
    }
   },
   "outputs": [],
   "source": [
    "def merger(d1, d2):\n",
    "    return d1.merge(d2, on='yyyymm', how='outer')\n",
    "\n",
    "df = reduce(merger, [pv_mobile_df, pc_mobile_df, pv_desktop_df, pc_desktop_df])\n",
    "    \n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add/remove columns as per the required schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:20.829091Z",
     "start_time": "2018-10-17T08:05:20.651722Z"
    }
   },
   "outputs": [],
   "source": [
    "df['pagecount_all_views'] = df['pagecount_mobile_views'] + df['pagecount_desktop_views']\n",
    "df['pageview_all_views'] = df['pageview_mobile_views'] + df['pageview_desktop_views']\n",
    "df['year'] = df.yyyymm.apply(str).apply(year)\n",
    "df['month'] = df.yyyymm.apply(str).apply(month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:20.840406Z",
     "start_time": "2018-10-17T08:05:20.832807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('200712', '201809')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_date, max_date = df.yyyymm.min(), df.yyyymm.max()\n",
    "min_date, max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:20.847432Z",
     "start_time": "2018-10-17T08:05:20.842591Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop('yyyymm', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally write it out into a single CSV file/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T08:05:20.863673Z",
     "start_time": "2018-10-17T08:05:20.849977Z"
    }
   },
   "outputs": [],
   "source": [
    "output_csv_filename = \"en-wikipedia_traffic_{from_date}-{to_date}.csv\".format(from_date=min_date, to_date=max_date)\n",
    "output_csv_filepath = os.path.join(OUTPUT_CSV_DIR, output_csv_filename)\n",
    "df.to_csv(output_csv_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
